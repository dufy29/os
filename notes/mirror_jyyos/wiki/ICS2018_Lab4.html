<html>
  <Head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

    
<link rel="stylesheet" href="../static/css/bootstrap.min.css"/>
<link rel="stylesheet" href="../static/css/bootstrap-theme.min.css"/>


    <link rel="stylesheet" href="../static/css/fonts/crmison.css"/>
    <link rel="stylesheet" href="../static/css/fonts/fira_code.css"/>
    <link rel="stylesheet" href="../static/css/fonts/ptsans.css"/>
    <link rel="stylesheet" href="../static/css/katex.min.css"/>
    <link rel="stylesheet" href="../static/css/wiki.css"/>
    <link rel="stylesheet" href="../static/css/codehilite.css"/>

    <script src="../static/js/jquery.min.js"></script>
    <script src="../static/js/bootstrap.bundle.min.js"></script>
    <script src="../static/js/katex.min.js"></script>
    
    

    <title>Lab4: Cache模拟器</title>
  </Head>
  <body>
   
   
<nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">
  <a class="navbar-barnd" href="index.html">Yanyan's Wiki</a>
  <div class="collapse navbar-collapse">
    <div class="navbar-nav">
      <a class="nav-item nav-link active" href="OS2020.html">
        <img class="textimg" src="../static/wiki/logo-n.png"/>
        操作系统 (2020)</a>
      <a class="nav-item nav-link active" href="SysLab2020.html">
        计算机系统综合实验 (2020)</a>
      <a class="nav-item nav-link active" href="ICS_NJU.html"><img class="textimg" height="18px" src="../static/img/ics.png"/> 加入我们</a>
    </div>
    <form class="form-inline" autocomplete="off">
      <input id="token-input" type="text" oninput="login();" maxlength="16"
        data-toggle="tooltip" data-placement="bottom"
        title="用于确定身份的作业提交 SHA-1 hash digest。更改后回车或刷新网页生效"></input>
    </form>
  </div>
</nav>

<center>
  <div class="article-container">
    <div class="article">
      <h1 id="lab4-cache">Lab4: Cache模拟器</h1>
<div class="fenced fenced-red">
<h4 id="_1">⚠️ 截止时间为期末考试前。</h4>
</div>
<h2 id="_2">提交</h2>
<div class="fenced fenced-red">
<h4 id="_3">提交方法</h4>
<p>将所有待提交的文件保存到同一目录中(包括以学号命名的pdf实验报告)，设置好<code>STUID</code>和<code>STUNAME</code>环境变量后，在命令行中(当前工作目录为提交文件所在目录)，执行</p>
<div class="codehilite"><pre><span></span><span class="err">bash -c &quot;$(curl -s http://moon.nju.edu.cn/people/yyjiang/teach/submit.sh)&quot;</span>
</pre></div>


<p>(复制上述命令，没有连字符)，输入<code>Lab4</code>提交(注意大小写)。</p>
</div>
<h3 id="_4">收到的提交</h3>
<table class="submissions"><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

<div class="fenced fenced-blue">
<h4 id="_5">故事背景</h4>
<p>(这个实验也是yzh从旧版PA里摘出来的，所以你们反正是逃不了的。)</p>
<p>怎样优化系统设计和实现让系统/程序运行得更快、怎样查找程序中的bug等是计算机系统和软件中的核心研究问题，而在程序运行时记录日志供之后分析是其中很重要的一种技术手段，这里有两个问题：</p>
<ol>
<li>怎样在程序运行时进行记录？除了手工在程序中添加printf之外，我们有很多<strong>自动</strong>的工具，例如程序插装工具、profiler等，都能输出某种形式的程序运行日志。例如，function call trace是函数调用的序列；memory trace是内存访问的序列 (这个实验中用到)。</li>
<li>在有了一个trace之后，怎样用记录的一次程序执行来指导系统的优化或是寻找系统中潜在的bug。</li>
</ol>
<p>这里有巨多的研究问题：怎么又快又好地得到我们想要的日志？怎样从日志中分析出对我们有用的信息，例如性能瓶颈、软件bug？</p>
</div>
<h2 id="_6">实验描述</h2>
<p>这个编程实验需要模拟实现一个简单的cache, 并尝试实现各种替换算法来优化程序的性能. 所谓模拟, 即我们已有所有内存访问的序列, 你需要“模拟”出cache的行为, 从而评估不同配置的cache对程序运行的影响.
请大家从<a href="../static/wiki/ics/ics2018-lab4.zip">框架代码</a>开始.</p>
<p>在代码目录下执行</p>
<div class="codehilite"><pre><span></span><span class="err">make</span>
</pre></div>


<p>来编译, 生成可执行文件<code>a.out</code>. 其运行方式如下</p>
<div class="codehilite"><pre><span></span><span class="p">.</span><span class="o">/</span><span class="n">a</span><span class="p">.</span><span class="k">out</span><span class="w"> </span><span class="o">[</span><span class="n">-r seed</span><span class="o">]</span><span class="w"> </span><span class="o">[</span><span class="n">trace</span><span class="o">]</span><span class="w"></span>
</pre></div>


<p>其中<code>seed</code>是随机种子, 可以用于确定性回放帮助调试, 缺省时会用系统时间作为种子;
<code>trace</code>是<code>bz2</code>压缩格式的访存序列, 缺省时会产生随机访存序列来测试.</p>
<div class="fenced fenced-red">
<h4 id="_7">不要解压缩</h4>
<p>已有的代码可以<strong>通过调用外部命令 (bzcat)</strong>直接读取压缩的日志文件。在一个程序里调用另一个程序似乎还是头一次，大家可以仔细阅读代码，其中使用了popen函数(RTFM)。</p>
</div>
<h3 id="cache">Cache的故事</h3>
<p>随着集成电路技术的发展, CPU越来越快;
另一方面, DRAM的速度却受限于它本身的<a href="http://computer.howstuffworks.com/ram.htm">工作原理</a>.
我们先简要解释一下这两者的差别.
DRAM的存储空间可以看成若干个二维矩阵(若干个bank), 矩阵中的每个元素包含一个晶体管和一个电容,
晶体管充当开关的作用, 功能上相当于读写使能;
电容用来存储一个bit, 当电容的电量大于50%, 就认为是<code>1</code>, 否则就认为是<code>0</code>.
但是电容是会漏电的, 如果不进行任何操作的话, 电容中的电量就会不断下降,
<code>1</code>最终会变成<code>0</code>, 存储数据就丢失了.
为了避免这种情况, DRAM必须定时刷新, 读出存储单元的每一个bit, 如果表示<code>1</code>, 就往里面充电.
DRAM每次读操作都会读出二维矩阵中的一行, 由于电容会漏电的特性,
在将一行数据读出之前, 还要对这一行的电容进行预充电,
防止在读出的过程中有的电容电量下降到50%以下而被误认为是<code>0</code>.</p>
<p>而CPU的寄存器采用的是SRAM, 是通过一个触发器来存储一个bit,
具体来说就是4-6个晶体管, 只要不断电, SRAM中的数据就不会丢失,
不需要定时刷新, 也不需要预充电, 读写速度随着主频的提升而提升.</p>
<p>由于RISC架构的指令少, 格式规整, 硬件的逻辑不算特别复杂, CPU做出来之后, 芯片上还多出了很多面积.
为了把这些面积利用起来, 架构师们提出了cache的概念,
把剩下的面积用于SRAM, 同时也为了弥补CPU和Memory之前性能的鸿沟.
CISC的运气就没那么好了, 指令多, 格式不规整, 硬件逻辑十分复杂,
在芯片上一时间腾不出地方来放cache, 所以你在i386手册上找不到和cache相关的内容.
当CISC架构师们意识到复杂的电路逻辑已经成为了提高性能的瓶颈时, 他们才向RISC取经, 把指令分解成微指令来执行:</p>
<div class="codehilite"><pre><span></span><span class="w">                              </span><span class="n">R</span><span class="o">[</span><span class="n">EAX</span><span class="o">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">M</span><span class="o">[</span><span class="n">var</span><span class="o">]</span><span class="w"></span>
<span class="n">addl</span><span class="w"> </span><span class="err">$</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="nf">var</span><span class="w">        </span><span class="o">=&gt;</span><span class="w">        </span><span class="n">R</span><span class="o">[</span><span class="n">EAX</span><span class="o">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">R</span><span class="o">[</span><span class="n">EAX</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>
<span class="w">                              </span><span class="n">M</span><span class="o">[</span><span class="n">var</span><span class="o">]</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">R</span><span class="o">[</span><span class="n">EAX</span><span class="o">]</span><span class="w"></span>
</pre></div>


<p>这样就减少了硬件的逻辑, 让微指令的执行流水化的同时, 也可以腾出面积来做cache了, 不过这些都是后话了.</p>
<h3 id="cache_1">Cache的思想和设计</h3>
<p>Cache工作方式实际上是局部性原理的应用:</p>
<ul>
<li>如果程序访问了一个内存区间, 那么这个内存区间很有可能在不久的将来会被再次访问, 这就是时间局部性.
  例如循环执行一小段代码, 或者是对一个变量进行读写(<code>addl $1, var</code>需要将 <code>var</code> 变量从内存中读出, 加1之后再写回内存).</li>
<li>如果程序访问了一个内存区间, 那么这个内存区间的相邻区间很有可能在不久的将来会被访问, 这就是空间局部性.
  例如顺序执行代码, 或者是扫描数组元素.</li>
</ul>
<p>相应的:</p>
<ul>
<li>为了利用时间局部性, cache将暂时存放从内存读出的数据,
  当CPU打算再次访问这些数据的时候, 它不需要去访问内存, 而是直接在cache中读出即可.
  就这样把数据一放, 那些小循环的执行速度马上提高了数十倍.</li>
<li>为了利用空间局部性, cache从内存中读数据的时候, 并不是CPU要多少读多少, 而是一次多读点.
  Cache向内存进行读写的基本单位是cache block(块).
  现代的cache设计还会在空闲的时候进行预取(prefetch), 当CPU一直在计算的时候,
  cache会趁这段时间向内存拿点数据, 将来CPU正好需要的话就不用再花时间拿了.</li>
</ul>
<p>这听起来很不错, 有了cache, 只要CPU访问cache的时候命中, 就不需要把大量时间花费在访存上面了.
不过为了保证cache的命中率, cache本身也需要处理很多问题, 例如:</p>
<ul>
<li>一个内存区域可以被映射到多少个cache block?
  少了容易冲突, 多了电路逻辑和功耗都会上升.
  对这个问题的回答划分了不同的cache组织方式, 包括direct-mapped(直接映射),
  set associative(组相联)和fully associative(全相联).</li>
<li>冲突的时候, 需要替换哪一个cache block?
  这个问题的回答涉及到替换算法, 最理想的情况是替换那个很长时间都没访问过的cache block, 这就是LRU算法.
  但这对硬件实现来说太复杂了, 对于8-way set associative来说,
  每一个set中的8个cache block都有<code>8! = 40320</code>种可能的访问情况,
  编码至少需要16个bit, 译码则需要更大的代价, 电路逻辑和时延都会上升.
  因此实际上会采用伪LRU算法, 近似记录cache block的访问情况, 从而降低硬件复杂度.
  也有研究表明, 随机替换的效果也不会很差.</li>
<li>写cache的时候要不要每次都写回到内存?
  这个问题涉及到写策略, write through(写通)策略要求每次cache的写操作都同时更新内存,
  cache中的数据和内存中的数据总是一致的;
  write back(写回)策略则等到cache block被替换才更新内存, 就节省了很多内存写操作,
  但数据一致性得不到保证, 最新的数据有可能在cache中.
  数据一致性在多核架构中是十分重要的,
  如果一个核通过访问内存拿到了一个过时的数据, 用它来进行运算得到的结果就是错误的.</li>
<li>写缺失的时候要不要在cache中分配一个cache block?
  分配就更容易引起冲突, 不分配就没有用到时间局部性.</li>
</ul>
<p>这些问题并没有完美的回答, 任何一个选择都是tradeoff,
想获得好处势必要付出相应的代价, 计算机就是这样一个公平的世界.</p>
<p>另一个值得考虑的问题是如何降低cache缺失的代价.
一种方法是采用多级的cache结构, 当L1 cache发生缺失时, 就去L2 cache中查找,
只有当L2 cache也发生缺失时, 才去访问内存.
L2 cache通常比L1 cache要大, 所以查找所花时间要多一些, 但怎么说也比访问内存要快.
还有一种方法是采用victim cache, 被替换的cache block先临时存放在victim cache中,
等到要访问那个不幸被替换的cache block的时候, 可以从victim cache中找回来.
实验数据表明, 仅仅是一个大小只有4项的victim cache,
对于direct-mapped组织方式的cache有十分明显的性能提升, 有时候可以节省高达90%的访存.</p>
<p>上面叙述的只是CPU cache, 事实上计算机世界到处蕴含着cache的思想.
在你阅读本页面的时候, 本页面的内容已经被存放到网页缓存中了;
使用<code>printf</code>并没有及时输出, 是因为每次只输出一个字符需要花很大的代价,
因此程序会将内容先放在输出缓存区, 等到缓冲区满了再输出, 这其实有点write back的影子.
像内存, 磁盘这些相对于CPU来说的"低速"硬件, 都有相应的硬件cache来提高性能.
例如现代的DRAM一般都包含以下两种功能:</p>
<ol>
<li>每个bank中都有一个行缓存, 读出一行的时候会把数据放到行缓存中,
   如果接下来的访存操作的目的数据正好在行缓存中, 就直接对行缓存进行操作, 而不需要再进行预充电.</li>
<li>采用burst(突发读写)技术, 每次读写DRAM的时候不仅读写目的存储单元,
   把其相邻的存储单元也一同进行读写, 这样对于一些物理存储连续的操作(例如数组),
   一次DRAM操作就可以读写多个存储单元了.</li>
</ol>
<p>明白cache存在的价值之后, 你就不难理解这些技术的意义了. 可惜的是, DRAM仍旧摆脱不了定时刷新的命运. </p>
<div class="fenced fenced-green">
<h4 id="_8">思考题: 数据对齐和存储层次结构</h4>
<p>想一想, 为什么编译器为变量分配存储空间的时候一般都会对齐?
访问一个没有对齐的存储空间会经历怎么样的过程?</p>
<p>关于cache具体如何工作, 课上都已经详细讲过, 这里就不另外叙述了.
值得一提的是维基百科中的<a href="http://en.wikipedia.org/wiki/CPU_cache">CPU cache</a>页面,
里面除了课堂上讲过的知识, 还有诸多延伸, 值得仔细琢磨.</p>
</div>
<div class="fenced fenced-red">
<h4 id="cache_2">实验要求: 实现cache</h4>
<p>在<code>cache.c</code>中实现如下函数</p>
<div class="codehilite"><pre><span></span><span class="c1">// 从cache中读出`addr`地址处的4字节数据</span>
<span class="c1">// 若缺失, 需要先从内存中读入数据</span>
<span class="kt">uint32_t</span> <span class="nf">cache_read</span><span class="p">(</span><span class="kt">uintptr_t</span> <span class="n">addr</span><span class="p">);</span>

<span class="c1">// 往cache中`addr`地址所属的块写入数据`data`, 写掩码为`wmask`</span>
<span class="c1">// 例如当`wmask`为`0xff`时, 只写入低8比特</span>
<span class="c1">// 若缺失, 需要从先内存中读入数据</span>
<span class="kt">void</span> <span class="nf">cache_write</span><span class="p">(</span><span class="kt">uintptr_t</span> <span class="n">addr</span><span class="p">,</span> <span class="kt">uint32_t</span> <span class="n">data</span><span class="p">,</span> <span class="kt">uint32_t</span> <span class="n">wmask</span><span class="p">);</span>

<span class="c1">// 初始化一个数据大小为`2^total_size_width`B, 关联度为`2^associativity_width`的cache</span>
<span class="c1">// 例如`init_cache(14, 2)`将初始化一个16KB, 4路组相联的cache</span>
<span class="c1">// 将所有valid bit置为无效即可</span>
<span class="kt">void</span> <span class="nf">init_cache</span><span class="p">(</span><span class="kt">int</span> <span class="n">total_size_width</span><span class="p">,</span> <span class="kt">int</span> <span class="n">associativity_width</span><span class="p">);</span>
</pre></div>


<p>另外cache的一些特性如下:</p>
<ul>
<li>块大小为64B(见<code>common.h</code>中<code>BLOCK_SIZE</code>的定义)</li>
<li>替换算法采用随机方式</li>
<li>写回, 写分配</li>
</ul>
<p><code>mem.c</code>中提供了如下两个函数, cache缺失/写回的时候需要用到它们:</p>
<div class="codehilite"><pre><span></span><span class="c1">// 从块号为`block_num`的内存地址中读出一整个cache块大小的内容到`buf`中</span>
<span class="kt">void</span> <span class="nf">mem_read</span><span class="p">(</span><span class="kt">uintptr_t</span> <span class="n">block_num</span><span class="p">,</span> <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">buf</span><span class="p">);</span>
<span class="c1">// 往块号为`block_num`的内存地址中写入一整个cache块大小的内容`buf`</span>
<span class="kt">void</span> <span class="nf">mem_write</span><span class="p">(</span><span class="kt">uintptr_t</span> <span class="n">block_num</span><span class="p">,</span> <span class="kt">uint8_t</span> <span class="o">*</span><span class="n">buf</span><span class="p">);</span>
</pre></div>


</div>
<p>在完成实现之后, 你就可以观察cache的各类性能指标: 缓存的缺失率等. 在实际的硬件实现中, 更复杂的缓存意味着更高的命中率, 但也意味着更低的访问速度. 虽然流水线技术能降低缓存对处理器频率的影响, 复杂的缓存降低了缺失的次数(提升了性能)的另一方面也降低了处理器的IPC (降低了性能). 计算机系统中总是有这样的trade-offs, 使设计高效的系统成为一个很大的挑战.</p>
<div class="fenced fenced-blue">
<h4 id="cache_3">提示: 如何测试你的cache实现</h4>
<p>框架代码提供了一套CPU接口<code>cpu_read()</code>和<code>cpu_write()</code>,
它们会调用你实现的<code>cache_read()</code>和<code>cache_write()</code>.
同时框架代码提供了一套uncache的接口<code>cpu_uncache_read()</code>和<code>cpu_uncache_write()</code>,
用于直接访问另一个独立的内存.
这样是为了对你的实现进行对比测试, 测试的主要思想是: 从CPU端来看, 有无cache并不影响读数据的结果.
因此, 框架代码会随机生成一些访存请求, 同时输入到两套CPU接口中, 并对比读接口的结果.
若在某一时刻发现读结果不一致, 就会触发"assertion failed".</p>
<p>另外为了方便调试, 我们允许将随机种子作为参数来运行cache程序,
如果使用相同的种子多次运行, 就会产生一样的随机数序列.</p>
</div>
<p>为了评估一个给定cache的性能, 你需要对以下几方面进行建模:</p>
<ol>
<li>cache的复杂性, 具体度量为访问cache所需的时间 (ns). 这会降低处理器的频率.</li>
<li>cache miss时的代价, 根据内存访问的时间建模.</li>
</ol>
<p>尝试修改cache的各种参数(例如把cache总大小改成256B等), 并为每一个模型估计它的访问时间, 然后根据你建立的模型计算给定workload的“运行时间”. 
根据你对计算机系统的理解, 给出对于microbench-test的workload下你认为最佳的cache设计.</p>
<div class="fenced fenced-green">
<h4 id="cache_4">不知道cache的复杂性对频率的影响?</h4>
<p>你可以建立带参数的模型, 例如假设associativity为<math>k</math>, 则访问时间为 <math>ak^2 + b</math>.
这样你可以考察<math>a</math>, <math>b</math>对cache性能的影响.</p>
</div>
<p>日志分析工具的好处在这里体现得淋漓尽致, 你可以轻而易举地修改一个cache的"构造", 马上重新开始统计新的数据, 而不需要做一个真正的cache才开始测试. 自从cache的概念被提出来, 无数的研究者提出了五花八门的cache, 学术界中研究cache的论文更是数不胜数, 但被工业界采纳的cache研究却寥寥无几, 究其原因只有一个 -- 纸上谈兵, 无法用硬件实现. </p>
    </div>
  </div>
</center>

<div class="footer-bottom">
  <center>
    <div class="copyright"> © 2020 Yanyan Jiang, All rights reserved </div>
  </center>
</div>


    <script>
      $(function () {
        $('[data-toggle="tooltip"]').tooltip()
      })

      $("math").each(function() {
        var tex = $(this).text();
        var html = katex.renderToString(tex, {
          displayMode: $(this).attr('class') == 'block-math',
          throwOnError: false
        });
        $(this).replaceWith(html);
      });

      function get_token() {
        var match = document.cookie.match(new RegExp('(^| )token=([^;]+)'));
        if (match) return match[2];
        else return "";
      }

      var token = get_token();
      var hint = "token", box = $("#token-input");

      if (token == "") { box.val(hint); }
      else { box.val(token); }

      function login() {
        var token = box.val()
        document.cookie = 'token=' + token + '; expires=Fri, 31 Dec 9999 23:59:59 GMT;';
        if (token == '') {
          box.val(hint);
        }
      }
    </script>
  </body>
</html>